# analytics_agent.py

from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage, AIMessage
from langchain_community.chat_models import AzureChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from .tools.analytics_tools import query_analytics, search_metadata, get_organisation_units
from dotenv import load_dotenv
from typing import List, TypedDict, Optional
import os

# Load environment variables
load_dotenv()


# Define the state structure for the graph
class AgentState(TypedDict):
    messages: List[BaseMessage]
    output: Optional[AIMessage]
    raw_data: dict  # or: Any, if it can vary



# Set up the LLM (Azure OpenAI GPT-4)
llm = AzureChatOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT_GPT_4O"),
    openai_api_version=os.getenv("OPENAI_API_VERSION"),
    model="gpt-4",
    temperature=0,
    max_tokens=4000,
)

# Tools available to the analytics agent
tools = [query_analytics, search_metadata, get_organisation_units]

# Instruction prompt for analytics tasks
system_prompt_text = """You are a DHIS2 analytics assistant. Your job is to query DHIS2 correctly using the provided tools.

Here’s how to operate:
- If a user gives natural terms (like "maternal deaths"), use `search_metadata` to find relevant metadata.
- You can filter metadata by type: "indicator", "dataElement", or "programIndicator".
- Use the returned metadata `id` as input for the `query_analytics` tool.
- Use `get_organisation_units` to find the correct orgUnit ID if a name like "Bo District" or "national" is mentioned.
- Do not guess values. Always use the correct `id` or `UID` from DHIS2.

Always respond with JSON data from DHIS2. Never fabricate data.

Examples of good tool usage:
- Use `search_metadata` if the user says "show maternal health indicators".
- Use `get_organisation_units` if the user says "in Bo District" or "level 2".
- Use `query_analytics` after resolving both `indicators` and `org_unit` IDs.

Be concise and accurate."""


# Prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt_text),
    MessagesPlaceholder(variable_name="messages"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# Create the agent
agent = create_openai_tools_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)


# # Define the graph node logic
# def agent_node(state: AgentState) -> AgentState:
#     try:
#         last_message = state["messages"][-1]
#         result = agent_executor.invoke({"messages": [last_message]})
#
#         # Improved response extraction
#         if isinstance(result, dict) and isinstance(result.get("output"), AIMessage):
#             response = result["output"].content
#         elif isinstance(result, dict):
#             response = str(result.get("output", result))
#         else:
#             response = str(result)
#
#         messages = state["messages"] + [AIMessage(content=response)]
#         return {"messages": messages}
#     except Exception as e:
#         error_message = f"❌ Error: {str(e)}"
#         messages = state["messages"] + [AIMessage(content=error_message)]
#         return {"messages": messages}





# def agent_node(state: AgentState) -> AgentState:
#     try:
#         result = agent_executor.invoke(state)
#
#         # 🌟 Ensure response is returned in the "output" key
#         if isinstance(result, dict) and "output" in result:
#             response_msg = result["output"]
#         elif isinstance(result, dict) and "messages" in result:
#             last_msg = result["messages"][-1]
#             response_msg = (
#                 last_msg if isinstance(last_msg, AIMessage)
#                 else AIMessage(content=str(last_msg))
#             )
#         else:
#             response_msg = AIMessage(content="⚠️ No response generated by the agent.")
#
#         # ✅ Match the metadata executor return signature
#         return {
#             "messages": state["messages"] + [response_msg],
#             "output": response_msg
#         }
#
#     except Exception as e:
#         error_msg = AIMessage(content=f"❌ Error: {e}")
#         return {
#             "messages": state["messages"] + [error_msg],
#             "output": error_msg
#         }



def agent_node(state: AgentState) -> AgentState:
    try:
        result = agent_executor.invoke(state)

        # Extract latest message to show to the user
        if isinstance(result, dict):
            response_msg = None
            tool_output = None

            # Final response message
            if "output" in result:
                response_msg = result["output"]
            elif "messages" in result:
                last_msg = result["messages"][-1]
                response_msg = (
                    last_msg if isinstance(last_msg, AIMessage)
                    else AIMessage(content=str(last_msg))
                )

            # Capture tool output if available
            if "intermediate_steps" in result:
                for step in result["intermediate_steps"]:
                    if isinstance(step, tuple) and step[0].tool == "query_analytics":
                        tool_output = step[1]  # This is the return value of your tool

            # Add both message and raw tool output to state
            # return {
            #     "messages": state["messages"] + [response_msg],
            #     "output": {
            #         "message": response_msg,
            #         "tool_data": tool_output  # 💡 You can now access full dict later
            #     }
            # }
            # print(tool_output)
            return {
                "messages": state["messages"] + [response_msg],
                "output": response_msg,
                "raw_data": tool_output

            }

        else:
            return {
                "messages": state["messages"] + [AIMessage(content="⚠️ Invalid result format.")],
                "output": None
            }

    except Exception as e:
        error_msg = AIMessage(content=f"❌ Error: {e}")
        return {
            "messages": state["messages"] + [error_msg],
            "output": error_msg
        }


# Build the stateful agent graph
graph = StateGraph(AgentState)
graph.add_node("agent", agent_node)
graph.set_entry_point("agent")
graph.add_edge("agent", END)

# Compile the graph and expose it
analytics_executor = graph.compile()

